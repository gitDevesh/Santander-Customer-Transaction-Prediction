{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'D:\\Data Science\\Edwisor\\Projects\\Customer Transaction Prediction')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-colonial",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-wholesale",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-advice",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-sapphire",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new dataframes\n",
    "df = df_train.drop(columns=['ID_code', 'target'], axis=1)\n",
    "test = df_test.drop(columns= 'ID_code', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-argentina",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-intake",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Missing Value Analysis\n",
    "df.isnull().sum().value_counts()\n",
    "\n",
    "# There are no missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are no missing values in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-state",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Outlier Analysis\n",
    "plt.figure(figsize=(30,400))\n",
    "for i in range(1,199):\n",
    "    i+=1\n",
    "    plt.subplot(67,3,i)\n",
    "    plt.boxplot(df[df.columns[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing outliers with nan\n",
    "for i in df.columns:\n",
    "   # print(i)\n",
    "    q75, q25 = np.percentile(df.loc[:,i], [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    min = q25 - (1.5*iqr)\n",
    "    max = q75 + (1.5*iqr)\n",
    "    \n",
    "    df.loc[df[i] < min, i] = np.nan\n",
    "    df.loc[df[i] > max, i] = np.nan\n",
    "    \n",
    "# Imputing values in nan\n",
    "df = df.loc[:i].fillna(df.loc[:i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing outliers with nan in test dataset\n",
    "for i in test.columns:\n",
    "   # print(i)\n",
    "    q75, q25 = np.percentile(test.loc[:,i], [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    min = q25 - (1.5*iqr)\n",
    "    max = q75 + (1.5*iqr)\n",
    "    \n",
    "    test.loc[test[i] < min, i] = np.nan\n",
    "    test.loc[test[i] > max, i] = np.nan\n",
    "    \n",
    "# Imputing values in nan\n",
    "test = test.loc[:i].fillna(test.loc[:i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-editor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's check if there is a class imbalance in the dataset\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.countplot(df_train['target'])\n",
    "\n",
    "# Percentage of class imbalance\n",
    "df_train['target'].value_counts()/len(df_train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see on the above plot and the percentage of two values in target variable there is a big class imbalance in the\n",
    "# dataset resulting in the model being biased and giving wrong predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHecking the correlation of variables in datasets\n",
    "corr = df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is low correlation between variables to a point where they are not correlated at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-ebony",
   "metadata": {},
   "source": [
    "# Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,150))\n",
    "for i in range(1,199):\n",
    "    plt.subplot(67,3,i+1)\n",
    "    sns.histplot(df[df.columns[i]], kde_kws={'bw': 0.05,'lw':2}, color='red')\n",
    "plt.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see the almost all of the data us uniformaly distributed but the values for each variable varies at different \n",
    "# ranges. So in order to make it better for the ML model the data needs to be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_std = pd.DataFrame(scaler.fit_transform(df))\n",
    "test_std = pd.DataFrame(scaler.fit_transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-mexico",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-class",
   "metadata": {},
   "source": [
    "# Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_std\n",
    "y = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-fireplace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know there is class imbalance problem which will make the model biased. Let us create a logistic model without treating\n",
    "# the imblance and a model with the imbalance problem treated to see how the model performs on both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us treat the imbalance in the dataset first. There are several ways to treat the class imbalance.\n",
    "# We are going to oversample the minority using SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-blink",
   "metadata": {},
   "source": [
    "# Treating Imbalanced Splitted Data using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-prevention",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train_sm, y_train_sm = sm.fit_sample(X_train, y_train)\n",
    "X_test_sm, y_test_sm = sm.fit_sample(X_test, y_test)\n",
    "print(X_train_sm.shape)\n",
    "print(X_test_sm.shape)\n",
    "print(y_train_sm.shape)\n",
    "print(y_test_sm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-stake",
   "metadata": {},
   "source": [
    "# Creating Model\n",
    "# 1) Logistic Regression with Class mbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lm = LogisticRegression(max_iter=100, random_state=21).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lm = model_lm.predict(X_test)\n",
    "pred_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_lm = accuracy_score(y_test, pred_lm)\n",
    "print('The accuracy score is: ', score_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy is not the best metric to evaluate the models' perfromance so we will introduce some new metrics\n",
    "# The metrics for evaluation being ROC Score, Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_lm = confusion_matrix(y_test, pred_lm)\n",
    "cm_lm = pd.crosstab(y_test, pred_lm)\n",
    "cm_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Score\n",
    "roc_score_lm = roc_auc_score(y_test, pred_lm)\n",
    "print('The roc score is ',roc_score_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "fpr_lm,rec_lm,thresh_lm=roc_curve(y_test,pred_lm)\n",
    "plt.plot(fpr_lm, rec_lm, label='Area under ROC curve = %0.3f)' %roc_score_lm)\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.legend()\n",
    "plt.title('ROC Curve')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate(Recall)')\n",
    "plt.show()\n",
    "print('The ROC score is ',roc_score_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The area under the ROC curve is 0.6262279562629977 and the f1-score for customers that will do transaction is also very\n",
    "# low compared to those who will not do the transaction which shows that the model will not perform well on imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-surgery",
   "metadata": {},
   "source": [
    "# Logistic Regression: Class Imbalance Treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lm_sm = LogisticRegression(max_iter=100, random_state=21).fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lm_sm = model_lm_sm.predict(X_test_sm)\n",
    "pred_lm_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_lm_sm = accuracy_score(y_test_sm, pred_lm_sm)\n",
    "print('The accuracy score is: ', score_lm_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "cm_lm_sm = confusion_matrix(y_test_sm, pred_lm_sm)\n",
    "cm_lm_sm = pd.crosstab(y_test_sm, pred_lm_sm)\n",
    "cm_lm_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_score_lm_sm = roc_auc_score(y_test_sm, pred_lm_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "fpr_lm_sm, rec_lm_sm, thresh_lm_sm = roc_curve(y_test_sm, pred_lm_sm)\n",
    "plt.plot(fpr_lm_sm, rec_lm_sm, label= 'Area under ROC curve: %0.3f' %roc_score_lm_sm)\n",
    "plt.legend()\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate(Recall)')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "print('The ROC score is: ',  roc_score_lm_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_sm, pred_lm_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see using SMOTE and over sampling the minority class the ROC score and the f1-score improved. Now f1-score for \n",
    "# both the customers who will do transaction and those who will not is high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-treatment",
   "metadata": {},
   "source": [
    "# 2) Random Forest Classifier with class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfc = RandomForestClassifier(random_state=21, n_estimators=10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rfc = model_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rfc = accuracy_score(y_test, pred_rfc)\n",
    "print('The accuracy score is: ', score_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_rfc = confusion_matrix(y_test, pred_rfc)\n",
    "cm_rfc = pd.crosstab(y_test, pred_rfc)\n",
    "cm_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_score_rfc = roc_auc_score(y_test, pred_rfc)\n",
    "print('The ROC score is: ', roc_score_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "fpr_rfc, rec_rfc, thresh_rfc = roc_curve(y_test, pred_rfc)\n",
    "plt.plot(fpr_rfc, rec_rfc, label = 'Area under ROC curve: %0.3f' %roc_score_rfc)\n",
    "plt.legend()\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Postive Rate(Recall)')\n",
    "plt.title('ROC Curve')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ROC score and curve clearly shows the model is preforming poorly. It is completely biased towards the majority class.\n",
    "# Let us use the same algorithm in the balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-detroit",
   "metadata": {},
   "source": [
    "# Random Forest Classifier : Class Imbalance Treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfc_sm = RandomForestClassifier(random_state=21, n_estimators=30).fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rfc_sm = model_rfc_sm.predict(X_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rfc_sm = accuracy_score(y_test_sm, pred_rfc_sm)\n",
    "print('The accuracy score is: ', score_rfc_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_rfc_sm = confusion_matrix(y_test_sm, pred_rfc_sm)\n",
    "cm_rfc_sm = pd.crosstab(y_test_sm, pred_rfc_sm)\n",
    "cm_rfc_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_score_rfc_sm = roc_auc_score(y_test_sm, pred_rfc_sm)\n",
    "print('The ROC score is: ', roc_score_rfc_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "fpr_rfc_smt, rec_rfc_smt, thresh_rfc_smt = roc_curve(y_test_sm, pred_rfc_sm)\n",
    "plt.plot(fpr_rfc_smt, rec_rfc_smt, label= 'Area under ROC curve: %0.3f' %roc_score_rfc_sm)\n",
    "plt.legend()\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate(Recall)')\n",
    "plt.title('ROC Cruve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_sm, pred_rfc_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even though the ROC score of balanced data is much better than imbalanced data, recall and f1-score are still not satisfactory\n",
    "# Between the two models the better model for this particular problem is Logistic Regression.\n",
    "\n",
    "# Let us try one more model to compare its performance with logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-interim",
   "metadata": {},
   "source": [
    "# 3) Naive Bayes with class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gnb = gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gnb = model_gnb.predict(X_test)\n",
    "pred_gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_gnb = accuracy_score(y_test, pred_gnb)\n",
    "print('The accuracy score is: ', score_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_gnb = confusion_matrix(y_test, pred_gnb)\n",
    "cm_gnb = pd.crosstab(y_test, pred_gnb)\n",
    "cm_gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_score_gnb = roc_auc_score(y_test, pred_gnb)\n",
    "print('The ROC score is %0.6f' %roc_score_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "fpr_gnb, rec_gnb, thresh_gnb = roc_curve(y_test, pred_gnb)\n",
    "plt.plot(fpr_gnb, rec_gnb, label = 'Area under ROC curve: %0.3f' %roc_score_gnb)\n",
    "plt.legend()\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('False Positive Rate', fontsize=11)\n",
    "plt.ylabel('True Positive Rate(Recall)',fontsize=11)\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_gnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-helen",
   "metadata": {},
   "source": [
    "# Naive Bayes : Class Imbalance Treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gnb_sm = gnb.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gnb_sm = gnb.predict(X_test_sm)\n",
    "pred_gnb_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_gnb_sm = accuracy_score(y_test_sm, pred_gnb_sm)\n",
    "print('The accuracy score is %0.5f' %score_gnb_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_gnb_sm = confusion_matrix(y_test_sm, pred_gnb_sm)\n",
    "cm_gnb_sm = pd.crosstab(y_test_sm, pred_gnb_sm)\n",
    "cm_gnb_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_score_gnb_sm = roc_auc_score(y_test_sm, pred_gnb_sm)\n",
    "print('The ROC score is %0.3f' %roc_score_gnb_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-wireless",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "fpr_gnb_sm, rec_gnb_sm, thresh_gnb_sm = roc_curve(y_test_sm, pred_gnb_sm)\n",
    "plt.plot(fpr_gnb_sm, rec_gnb_sm, label = 'Area under ROC curve: %0.3f' %roc_score_gnb_sm)\n",
    "plt.legend()\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('False Postive Rate', fontsize = 11)\n",
    "plt.ylabel('True Positive Rate', fontsize = 11)\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_sm, pred_gnb_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-modification",
   "metadata": {},
   "source": [
    "# Predicting target on test data using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model_gnb_sm.predict(test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted = pd.DataFrame({'ID Code' : df_test['ID_code'].values})\n",
    "df_predicted['target'] = test_pred\n",
    "df_predicted.to_csv('Predicted Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted.sum().value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
